{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES = ['data/prediction_model_01.csv', 'data/prediction_model_02.csv', 'data/prediction_model_03.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENRES = ['Action',\n",
    " 'Adventure',\n",
    " 'Animation',\n",
    " 'Biography',\n",
    " 'Comedy',\n",
    " 'Crime',\n",
    " 'Documentary',\n",
    " 'Drama',\n",
    " 'Family',\n",
    " 'Fantasy',\n",
    " 'History',\n",
    " 'Horror',\n",
    " 'Music',\n",
    " 'Musical',\n",
    " 'Mystery',\n",
    " 'News',\n",
    " 'Romance',\n",
    " 'Sci-Fi',\n",
    " 'Sport',\n",
    " 'Thriller',\n",
    " 'War',\n",
    " 'Reality-TV',\n",
    " 'Western']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_macro_precision(path):\n",
    "    \n",
    "    #TP = actual genre when correct is 1 [INDEX 0]\n",
    "    #FP = predicted value when correct is 0 [INDEX 1]\n",
    "    #FN = actual genres when correct is 0 [INDEX 2]\n",
    "\n",
    "    # precision = TP/(TP+FP)\n",
    "    # recall = TP/ (TP+FN)\n",
    "    # F1 = (precision * recall)/(precision + recall)\n",
    "    \n",
    "    genre_map = {genre:[0,0,0] for genre in GENRES}\n",
    "\n",
    "    df = pd.read_csv(path)\n",
    "\n",
    "    for i, line in df.iterrows():\n",
    "        \n",
    "        correct = bool(line['correct?'])\n",
    "        predicted = line['predicted'][0]\n",
    "        actual = eval(line['actual genres'])\n",
    "        \n",
    "        if predicted not in genre_map:\n",
    "            genre_map[predicted] = [0,0,0]\n",
    "        \n",
    "        if correct:\n",
    "            for genre in actual:\n",
    "                genre_map[genre][0] += 1\n",
    "        else:\n",
    "            genre_map[predicted][1] += 1\n",
    "            \n",
    "            for genre in actual:\n",
    "                try:\n",
    "                    genre_map[genre][2] += 1\n",
    "                except KeyError:\n",
    "                    genre_map[genre] = [0,0,0]\n",
    "                    genre_map[genre][2] += 1\n",
    "                    \n",
    "                    \n",
    "    precision_lst, recall_lst, f1_lst = [], [], []\n",
    "    for key in genre_map:\n",
    "        TP = genre_map[key][0]\n",
    "        FP = genre_map[key][1]\n",
    "        FN = genre_map[key][2]\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            precision = TP/(TP+FP)\n",
    "        except ZeroDivisionError:\n",
    "            precision = 0\n",
    "        try:\n",
    "            recall = TP/(TP+FN)\n",
    "        except ZeroDivisionError:\n",
    "            recall = 0\n",
    "        try:\n",
    "            f1 = (2* precision * recall)/(precision+recall)\n",
    "        except ZeroDivisionError:\n",
    "            f1 = 0\n",
    "        \n",
    "        precision_lst.append(precision)\n",
    "        recall_lst.append(recall)\n",
    "        f1_lst.append(f1)\n",
    "        \n",
    "    precision_avg = sum(precision_lst)/len(precision_lst)\n",
    "    recall_avg = sum(recall_lst)/len(recall_lst)\n",
    "    f1_avg = sum(f1_lst)/len(f1_lst)\n",
    "        \n",
    "    return(precision_avg, recall_avg, f1_avg)\n",
    "        \n",
    "\n",
    "def get_micro_precision(path):\n",
    "    \n",
    "    #TP = actual genre when correct is 1 [INDEX 0]\n",
    "    #FP = predicted value when correct is 0 [INDEX 1]\n",
    "    #FN = actual genres when correct is 0 [INDEX 2]\n",
    "    \n",
    "    TP = 0\n",
    "    FP = 0\n",
    "    FN = 0\n",
    "    df = pd.read_csv(path)\n",
    "    \n",
    "    for i, line in df.iterrows():\n",
    "        correct = bool(line['correct?'])\n",
    "        predicted = line['predicted'][0]\n",
    "        actual = eval(line['actual genres'])\n",
    "        \n",
    "        if correct:\n",
    "            TP += 1\n",
    "        else:\n",
    "            FP +=1\n",
    "            for genre in actual:\n",
    "                FN+=1\n",
    "\n",
    "    # precision = TP/(TP+FP)\n",
    "    # recall = TP/ (TP+FN)\n",
    "    # F1 = (precision * recall)/(precision + recall)\n",
    "    \n",
    "    precision = TP/(TP+FP)\n",
    "    recall = TP/(TP+FN)\n",
    "    f1 = (2*precision*recall)/(precision+recall)\n",
    "    \n",
    "    return(precision, recall, f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preciction Model #1 Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Macro Average</th>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.052320</td>\n",
       "      <td>0.094596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro Average</th>\n",
       "      <td>0.085942</td>\n",
       "      <td>0.042464</td>\n",
       "      <td>0.056842</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Precision    Recall  F1 Score\n",
       "Macro Average   0.527778  0.052320  0.094596\n",
       "Micro Average   0.085942  0.042464  0.056842"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro = get_macro_precision(\"data/prediction_model_01.csv\")\n",
    "micro = get_micro_precision(\"data/prediction_model_01.csv\")\n",
    "\n",
    "labels = ['Precision', 'Recall', 'F1 Score']\n",
    "\n",
    "df = pd.DataFrame([macro, micro], columns=labels, index=['Macro Average', 'Micro Average'])\n",
    "print(\"Preciction Model #1 Scores\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preciction Model #2 Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Macro Average</th>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.320478</td>\n",
       "      <td>0.411542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro Average</th>\n",
       "      <td>0.551724</td>\n",
       "      <td>0.385043</td>\n",
       "      <td>0.453554</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Precision    Recall  F1 Score\n",
       "Macro Average   0.600000  0.320478  0.411542\n",
       "Micro Average   0.551724  0.385043  0.453554"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro = get_macro_precision(\"data/prediction_model_02.csv\")\n",
    "micro = get_micro_precision(\"data/prediction_model_02.csv\")\n",
    "\n",
    "labels = ['Precision', 'Recall', 'F1 Score']\n",
    "\n",
    "df = pd.DataFrame([macro, micro], columns=labels, index=['Macro Average', 'Micro Average'])\n",
    "\n",
    "print(\"Preciction Model #2 Scores\")\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preciction Model #3 Scores\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1 Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Macro Average</th>\n",
       "      <td>0.800000</td>\n",
       "      <td>0.377784</td>\n",
       "      <td>0.48732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Micro Average</th>\n",
       "      <td>0.498143</td>\n",
       "      <td>0.331451</td>\n",
       "      <td>0.39805</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Precision    Recall  F1 Score\n",
       "Macro Average   0.800000  0.377784   0.48732\n",
       "Micro Average   0.498143  0.331451   0.39805"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro = get_macro_precision(\"data/prediction_model_03.csv\")\n",
    "micro = get_micro_precision(\"data/prediction_model_03.csv\")\n",
    "\n",
    "labels = ['Precision', 'Recall', 'F1 Score']\n",
    "\n",
    "df = pd.DataFrame([macro, micro], columns=labels, index=['Macro Average', 'Micro Average'])\n",
    "\n",
    "print(\"Preciction Model #3 Scores\")\n",
    "\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
